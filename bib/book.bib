@inproceedings{compilingWithoutCont,
author = {Maurer, Luke and Downen, Paul and Ariola, Zena M. and Peyton Jones, Simon},
title = {Compiling without Continuations},
year = {2017},
isbn = {9781450349888},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3062341.3062380},
doi = {10.1145/3062341.3062380},
abstract = {Many fields of study in compilers give rise to the concept of a join point—a place where different execution paths come together. Join points are often treated as functions or continuations, but we believe it is time to study them in their own right. We show that adding join points to a direct-style functional intermediate language is a simple but powerful change that allows new optimizations to be performed, including a significant improvement to list fusion. Finally, we report on recent work on adding join points to the intermediate language of the Glasgow Haskell Compiler.},
booktitle = {Proceedings of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {482–494},
numpages = {13},
keywords = {CPS, ANF, Haskell, GHC, list fusion, intermediate languages},
location = {Barcelona, Spain},
series = {PLDI 2017}
}


@article{jones1992implementing,
author = {Jones, Peyton and L, Simon and Peyton Jones, Simon},
title = {Implementing Lazy Functional Languages on Stock Hardware: The Spineless Tagless G-machine},
year = {1992},
month = {July},
abstract = {The Spineless Tagless G-machine is an abstract machine designed to
                  support non- strict higher-order functional languages. This
                  presentation of the machine falls into three parts. Firstly,
                  we give a general discussion of the design issues involved in
                  implementing non-strict functional languages.Next, we
                  present the STG language, an austere but
                  recognisably-functional language, which as well as a
                  denotational meaning has a well-defined operational semantics.
                  The STG language is the \abstract machine code" for the
                  Spineless Tagless G-machine.Lastly, we discuss the mapping
                  of the STG language onto stock hardware. The success of an
                  abstract machine model depends largely on how efficient this
                  mapping can be made, though this topic is often relegated to a
                  short section. Instead, we give a detailed discussion of the
                  design issues and the choices we have made. Our principal
                  target is the C language, treating the C compiler as a
                  portable assembler.},
publisher = {Cambridge University Press},
url = {https://www.microsoft.com/en-us/research/publication/implementing-lazy-functional-languages-on-stock-hardware-the-spineless-tagless-g-machine/},
pages = {127-202},
journal = {Journal of Functional Programming},
volume = {2},
edition = {Journal of Functional Programming},
}

@article{GHCInliner,
author = {Peyton Jones, Simon and Marlow, Simon},
title = {Secrets of the Glasgow Haskell Compiler Inliner},
year = {2002},
issue_date = {July 2002},
publisher = {Cambridge University Press},
address = {USA},
volume = {12},
number = {5},
issn = {0956-7968},
url = {https://doi.org/10.1017/S0956796802004331},
doi = {10.1017/S0956796802004331},
abstract = {Higher-order languages such as Haskell encourage the programmer to
                  build abstractions by composing functions. A good compiler
                  must inline many of these calls to recover an efficiently
                  executable program. In principle, inlining is dead simple:
                  just replace the call of a function by an instance of its
                  body. But any compiler-writer will tell you that inlining is a
                  black art, full of delicate compromises that work together to
                  give good performance without unnecessary code bloat. The
                  purpose of this paper is, therefore, to articulate the key
                  lessons we learned from a full-scale “production” inliner, the
                  one used in the Glasgow Haskell compiler. We focus mainly on
                  the algorithmic aspects, but we also provide some indicative
                  measurements to substantiate the importance of various aspects
                  of the inliner.},
journal = {J. Funct. Program.},
month = {jul},
pages = {393–434},
numpages = {42}
}

@article{peytonjones1997a,
author = {Peyton Jones, Simon and Santos, Andre},
title = {A transformation-based optimiser for Haskell},
year = {1997},
month = {October},
abstract = {Many compilers do some of their work by means of
                  correctness-preserving, and hopefully performance-improving,
                  program transformations. The Glasgow Haskell Compiler (GHC)
                  takes this idea of "compilation by transformation" as its
                  war-cry, trying to express as much as possible of the
                  compilation process in the form of program transformations.
                  This paper reports on our practical experience of the
                  transformational approach to compilation, in the context of a
                  substantial compiler. This is a journal version of
                  "Compilation by program transformation: a report from the
                  trenches" (ESOP'96)},
url = {https://www.microsoft.com/en-us/research/publication/a-transformation-based-optimiser-for-haskell/},
journal = {Science of Computer Programming},
volume = {32},
number = {1},
}

@phdthesis{santos1995compilation,
author = {Santos, Andre and Peyton Jones, Simon},
title = {Compilation by transformation for non-strict functional languages},
organization = {University of Glasgow},
year = {1995},
month = {July},
abstract = {In this thesis we present and analyse a set of automatic
                  source-to-source program transformations that are suitable for
                  incorporation in optimising compilers for lazy functional
                  languages.  These transformations improve the quality of code
                  in many different respects, such as execution time and memory
                  usage. The transformations presented are divided into two
                  sets: global transformations, which are performed once (or
                  perhaps twice) during compilation; and a set of local
                  transformations with are performed before and after each of
                  the global transformations, so that they can simplify the code
                  before applying the global transformations, and take advantage
                  of them afterwards. Many of the local transformations are
                  simple, well known, and do not have major effects on their
                  own.  They become important as they interact with each other
                  and with global transformations, sometimes in non-obvious
                  ways.  We present how and why they improve the code, and
                  perform extensive experiments with real application
                  programs. We describe four global transformations, two of
                  which have not been used in any lazy functional compiler we
                  know of: the static argument transformations and let-floating
                  transformations.  The other two are well known for lazy
                  functional languages, but no major studies of their effects
                  have been performed: full laziness and lambda lifting.  We
                  also study and measure the effects of different inlining
                  strategies. We also present a Cost Semantics as a way to
                  reason about the effects of program transformations in lazy
                  functional languages.},
url = {https://www.microsoft.com/en-us/research/publication/compilation-transformation-non-strict-functional-languages/},
}

@inproceedings{SpinelessTaglessGMachine,
author = {Peyton Jones, Simon L. and Salkild, Jon},
title = {The Spineless Tagless G-Machine},
year = {1989},
isbn = {0897913280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/99370.99385},
doi = {10.1145/99370.99385},
booktitle = {Proceedings of the Fourth International Conference on Functional
                  Programming Languages and Computer Architecture},
pages = {184–201},
numpages = {18},
location = {Imperial College, London, United Kingdom},
series = {FPCA '89}
}

@misc{partain1996let-floating,
author = {Partain, WD and Santos, A and Peyton Jones, Simon},
title = {Let-floating: moving bindings to give faster programs},
year = {1996},
month = {May},
abstract = {Virtually every compiler performs transformations on the program it
                  is compiling in an attempt to improve efficiency. Despite
                  their importance, however, there have been few systematic
                  attempts to categorise such transformations and measure their
                  impact. In this paper we describe a particular group of
                  transformations - the "let-floating" transformations - and
                  give detailed measurements of their effect in an optimising
                  compiler for the non-strict functional language Haskell.
                  Let-floating has not received much explicit attention in the
                  past, but our measurements show that it is an important group
                  of transformations (at least for lazy languages), offering a
                  reduction of more than 30% in heap allocation and 15% in
                  execution time.},
publisher = {ACM Press},
url = {https://www.microsoft.com/en-us/research/publication/let-floating-moving-bindings-to-give-faster-programs/},
edition = {ACM SIGPLAN International Conference on Functional Programming (ICFP'96)},
note = {ACM SIGPLAN International Conference on Functional Programming (ICFP'96)},
}

@article{levityPolymorphism,
author = {Eisenberg, Richard A. and Peyton Jones, Simon},
title = {Levity Polymorphism},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/3140587.3062357},
doi = {10.1145/3140587.3062357},
abstract = {Parametric polymorphism is one of the linchpins of modern typed programming, but it comes with a real performance penalty. We describe this penalty; offer a principled way to reason about it (kinds as calling conventions); and propose levity polymorphism. This new form of polymorphism allows abstractions over calling conventions; we detail and verify restrictions that are necessary in order to compile levity-polymorphic functions. Levity polymorphism has created new opportunities in Haskell, including the ability to generalize nearly half of the type classes in GHC's standard library.},
journal = {SIGPLAN Not.},
month = {jun},
pages = {525–539},
numpages = {15},
keywords = {compilation, unboxed types, polymorphism}
}

@article{dataAbstractionRevisited,
author = {Cook, William R.},
title = {On Understanding Data Abstraction, Revisited},
year = {2009},
issue_date = {October 2009},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {10},
issn = {0362-1340},
url = {https://doi.org/10.1145/1639949.1640133},
doi = {10.1145/1639949.1640133},
abstract = {In 1985 Luca Cardelli and Peter Wegner, my advisor, published an ACM Computing Surveys paper called "On understanding types, data abstraction, and polymorphism". Their work kicked off a flood of research on semantics and type theory for object-oriented programming, which continues to this day. Despite 25 years of research, there is still widespread confusion about the two forms of data abstraction, abstract data types and objects. This essay attempts to explain the differences and also why the differences matter.},
journal = {SIGPLAN Not.},
month = {oct},
pages = {557–572},
numpages = {16},
keywords = {object, class, abstract data type, ADT}
}

@article{pointerTaggingLaziness
author = {Marlow, Simon and Yakushev, Alexey Rodriguez and Peyton Jones, Simon},
title = {Faster Laziness Using Dynamic Pointer Tagging},
year = {2007},
issue_date = {September 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {9},
issn = {0362-1340},
url = {https://doi.org/10.1145/1291220.1291194},
doi = {10.1145/1291220.1291194},
abstract = {In the light of evidence that Haskell programs compiled by GHC exhibit large numbers of mispredicted branches on modern processors, we re-examine the "tagless" aspect of the STG-machine that GHC uses as its evaluation model.We propose two tagging strategies: a simple strategy called semi-tagging that seeks to avoid one common source of unpredictable indirect jumps, and a more complex strategy called dynamic pointer-tagging that uses the spare low bits in a pointer to encode information about the pointed-to object. Both of these strategies have been implemented and exhaustively measured in the context of a production compiler, GHC, and the paper contains detailed descriptions of the implementations. Our measurements demonstrate significant performance improvements (14% for dynamic pointer-tagging with only a 2% increase in code size), and we further demonstrate that much of the improvement can be attributed to the elimination of mispredicted branch instructions.As part of our investigations we also discovered that one optimisation in the STG-machine, vectored-returns, is no longer worthwhile and we explain why.},
journal = {SIGPLAN Not.},
month = {oct},
pages = {277–288},
numpages = {12}
}

@InProceedings{lambdaLifting,
author="Johnsson, Thomas",
editor="Jouannaud, Jean-Pierre",
title="Lambda lifting: Transforming programs to recursive equations",
booktitle="Functional Programming Languages and Computer Architecture",
year="1985",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="190--203",
abstract="Lambda lifting is a technique for transforming a functional program with local function definitions, possibly with free variables in the function definitions, into a program consisting only of global function (combinator) definitions which will be used as rewrite rules. Different ways of doing lambda lifting are presented, as well as reasons for rejecting or selecting the method used in our Lazy ML compiler. A functional program implementing the chosen algorithm is given.",
isbn="978-3-540-39677-2"
}

@misc{selectiveLambdaLifting,
  doi = {10.48550/ARXIV.1910.11717},
  url = {https://arxiv.org/abs/1910.11717},
  author = {Graf, Sebastian and Jones, Simon Peyton},
  keywords = {Programming Languages (cs.PL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Selective Lambda Lifting},
  publisher = {arXiv},
  year = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{callArityVsDemandAnalysis,
  title = {Call Arity vs. Demand Analysis},
  year = {2017},
  month = aug,
  author = {Sebastian Graf},
  school = {Karlsruher Institut f{\"u}r Technologie (KIT)},
  institution = {IPD Snelting},
}

@inproceedings{fastCurry,
author = {Marlow, Simon and Jones, Simon Peyton},
title = {Making a Fast Curry: Push/Enter vs. Eval/Apply for Higher-Order Languages},
year = {2004},
isbn = {1581139055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1016850.1016856},
doi = {10.1145/1016850.1016856},
abstract = {Higher-order languages that encourage currying are implemented using one of two basic evaluation models: push/enter or eval/apply. Implementors use their intuition and qualitative judgements to choose one model or the other.Our goal in this paper is to provide, for the first time, a more substantial basis for this choice, based on our qualitative and quantitative experience of implementing both models in a state-of-the-art compiler for Haskell.Our conclusion is simple, and contradicts our initial intuition: compiled implementations should use eval/apply.},
booktitle = {Proceedings of the Ninth ACM SIGPLAN International Conference on Functional Programming},
pages = {4–15},
numpages = {12},
location = {Snow Bird, UT, USA},
series = {ICFP '04}
}

@article{hoCardinality,
author = {Sergey, Ilya and Vytiniotis, Dimitrios and Peyton Jones, Simon},
title = {Modular, Higher-Order Cardinality Analysis in Theory and Practice},
year = {2014},
issue_date = {January 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0362-1340},
url = {https://doi.org/10.1145/2578855.2535861},
doi = {10.1145/2578855.2535861},
abstract = {Since the mid '80s, compiler writers for functional languages (especially lazy ones) have been writing papers about identifying and exploiting thunks and lambdas that are used only once. However it has proved difficult to achieve both power and simplicity in practice. We describe a new, modular analysis for a higher-order language, which is both simple and effective, and present measurements of its use in a full-scale, state of the art optimising compiler. The analysis finds many single-entry thunks and one-shot lambdas and enables a number of program optimisations.},
journal = {SIGPLAN Not.},
month = {jan},
pages = {335–347},
numpages = {13},
keywords = {lazy evaluation, haskell, functional programming languages, compilers, static analysis, cardinality analysis, program optimisation, operational semantics, types and effects, thunks}
}

@book{okasaki,
place={Cambridge},
title={Purely Functional Data Structures},
DOI={10.1017/CBO9780511530104},
publisher={Cambridge University Press},
author={Okasaki, Chris},
year={1998}
}

@techreport{BagwellHAMT,
  title={Ideal hash trees},
  author={Bagwell, Phil},
  institution={Ecole polytechnique fédérale de Lausanne},
  year={2001}
}

@inproceedings{historyOfHaskell,
author = {Hudak, Paul and Hughes, John and Peyton Jones, Simon and Wadler, Philip},
title = {A History of Haskell: Being Lazy with Class},
year = {2007},
isbn = {9781595937667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1238844.1238856},
doi = {10.1145/1238844.1238856},
abstract = {This paper describes the history of Haskell, including its genesis and principles, technical contributions, implementations and tools, and applications and impact.},
booktitle = {Proceedings of the Third ACM SIGPLAN Conference on History of Programming Languages},
pages = {12–1–12–55},
location = {San Diego, California},
series = {HOPL III}
}
